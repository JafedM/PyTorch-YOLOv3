{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from detect import *\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def _draw_and_save_output_images(img_detections, imgs, img_size, output_path, classes):\n",
    "    \"\"\"Draws detections in output images and stores them.\n",
    "\n",
    "    :param img_detections: List of detections\n",
    "    :type img_detections: [Tensor]\n",
    "    :param imgs: List of paths to image files\n",
    "    :type imgs: [str]\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param output_path: Path of output directory\n",
    "    :type output_path: str\n",
    "    :param classes: List of class names\n",
    "    :type classes: [str]\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through images and save plot of detections\n",
    "    for (image_path, detections) in zip(imgs, img_detections):\n",
    "        print(f\"Image {image_path}:\")\n",
    "        _draw_and_save_output_image(\n",
    "            image_path, detections, img_size, output_path, classes)\n",
    "\n",
    "\n",
    "def _draw_and_save_output_image(image_path, detections, img_size, output_path, classes):\n",
    "    \"\"\"Draws detections in output image and stores this.\n",
    "\n",
    "    :param image_path: Path to input image\n",
    "    :type image_path: str\n",
    "    :param detections: List of detections on image\n",
    "    :type detections: [Tensor]\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param output_path: Path of output directory\n",
    "    :type output_path: str\n",
    "    :param classes: List of class names\n",
    "    :type classes: [str]\n",
    "    \"\"\"\n",
    "    # Create plot\n",
    "    img = np.array(Image.open(image_path))\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    # Rescale boxes to original image\n",
    "    detections = rescale_boxes(detections, img_size, img.shape[:2])\n",
    "    unique_labels = detections[:, -1].cpu().unique()\n",
    "    n_cls_preds = len(unique_labels)\n",
    "    # Bounding-box colors\n",
    "    cmap = plt.get_cmap(\"tab20b\")\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, n_cls_preds)]\n",
    "    bbox_colors = random.sample(colors, n_cls_preds)\n",
    "    for x1, y1, x2, y2, conf, cls_pred in detections:\n",
    "\n",
    "        print(f\"\\t+ Label: {classes[int(cls_pred)]} | Confidence: {conf.item():0.4f}\")\n",
    "\n",
    "        box_w = x2 - x1\n",
    "        box_h = y2 - y1\n",
    "\n",
    "        color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "        # Create a Rectangle patch\n",
    "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor=\"none\")\n",
    "        # Add the bbox to the plot\n",
    "        ax.add_patch(bbox)\n",
    "        # Add label\n",
    "        plt.text(\n",
    "            x1,\n",
    "            y1,\n",
    "            s=f\"{classes[int(cls_pred)]}: {conf:.2f}\",\n",
    "            color=\"white\",\n",
    "            verticalalignment=\"top\",\n",
    "            bbox={\"color\": color, \"pad\": 0})\n",
    "\n",
    "    # Save generated image with detections\n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    filename = os.path.basename(image_path).split(\".\")[0]\n",
    "    output_path = os.path.join(output_path, f\"{filename}.png\")\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", pad_inches=0.0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _create_data_loader(img_path, batch_size, img_size, n_cpu):\n",
    "    \"\"\"Creates a DataLoader for inferencing.\n",
    "\n",
    "    :param img_path: Path to file containing all paths to validation images.\n",
    "    :type img_path: str\n",
    "    :param batch_size: Size of each image batch\n",
    "    :type batch_size: int\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param n_cpu: Number of cpu threads to use during batch generation\n",
    "    :type n_cpu: int\n",
    "    :return: Returns DataLoader\n",
    "    :rtype: DataLoader\n",
    "    \"\"\"\n",
    "    dataset = ImageFolder(\n",
    "        img_path,\n",
    "        transform=transforms.Compose([DEFAULT_TRANSFORMS, Resize(img_size)]))\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=n_cpu,\n",
    "        pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Detect objects on images.\")\n",
    "parser.add_argument(\"-m\", \"--model\", type=str, default=\"../config/yolov3.cfg\", help=\"Path to model definition file (.cfg)\")\n",
    "parser.add_argument(\"-w\", \"--weights\", type=str, default=\"../weights/yolov3.weights\", help=\"Path to weights or checkpoint file (.weights or .pth)\")\n",
    "parser.add_argument(\"-i\", \"--images\", type=str, default=\"../data/samples\", help=\"Path to directory with images to inference\")\n",
    "parser.add_argument(\"-c\", \"--classes\", type=str, default=\"../data/coco.names\", help=\"Path to classes label file (.names)\")\n",
    "parser.add_argument(\"-o\", \"--output\", type=str, default=\"../output_yolov3\", help=\"Path to output directory\")\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int, default=1, help=\"Size of each image batch\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"Size of each image dimension for yolo\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"Number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.5, help=\"Object confidence threshold\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"IOU threshold for non-maximum suppression\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(f\"Command line arguments: {args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_path      = args.model\n",
    "weights_path    = args.weights\n",
    "img_path        = args.images\n",
    "classes         = load_classes(args.classes)\n",
    "output_path     = args.output\n",
    "batch_size      = args.batch_size\n",
    "img_size        = args.img_size\n",
    "n_cpu           = args.n_cpu\n",
    "conf_thres      = args.conf_thres\n",
    "nms_thres       = args.nms_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataloader = _create_data_loader(img_path, batch_size, img_size, n_cpu)\n",
    "model = load_model(model_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, model.hyperparams['height'], model.hyperparams['height']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img_detections, imgs = detect(\n",
    "                            model,\n",
    "                            dataloader,\n",
    "                            output_path,\n",
    "                            conf_thres,\n",
    "                            nms_thres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_draw_and_save_output_images(\n",
    "    img_detections, imgs, img_size, output_path, classes)\n",
    "\n",
    "print(f\"---- Detections were saved to: '{output_path}' ----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteccion analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "img_detections = []  # Stores detections for each image index\n",
    "imgs = []  # Stores image paths\n",
    "\n",
    "for (img_paths, input_imgs) in tqdm.tqdm(dataloader, desc=\"Detecting\"):\n",
    "    # Configure input\n",
    "    input_imgs = Variable(input_imgs.type(Tensor))\n",
    "\n",
    "    # Get detections\n",
    "    with torch.no_grad():\n",
    "        print('Hola')\n",
    "        detections = model(input_imgs)\n",
    "        #detections = non_max_suppression(detections, conf_thres, nms_thres)\n",
    "        \n",
    "    break\n",
    "\n",
    "    ## Store image and detections\n",
    "    #img_detections.extend(detections)\n",
    "    #imgs.extend(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detections.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamano [1, 10647, 85] resulta de aplanar y juntar las salidas de la red que son:\n",
    "    Darknet-225  [[-1, 3, 13, 13, 85], [-1, 3, 26, 26, 85], [-1, 3, 52, 52, 85]]\n",
    "Asi se tienen todas las posibles bounding box para cada una de las 80 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detections[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros 4 son los x, y, w, h  centro y tamano del bounding box\n",
    "\n",
    "El 5 elemento es la confianza de que se presente algun objeto\n",
    "\n",
    "Los demas 80 elementos son las probabilidades de las clases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non max supresion (esta en utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None):\n",
    "    \"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "\n",
    "    # Settings\n",
    "    # (pixels) minimum and maximum box width and height\n",
    "    max_wh = 4096\n",
    "    max_det = 300  # maximum number of detections per image\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 1.0  # seconds to quit after\n",
    "    multi_label = nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6), device=\"cpu\")] * prediction.shape[0]\n",
    "\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[x[..., 4] > conf_thres]  # confidence\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            # sort by confidence\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * max_wh  # classes\n",
    "        # boxes (offset by class), scores\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "\n",
    "        output[xi] = to_cpu(x[i])\n",
    "\n",
    "        if (time.time() - t) > time_limit:\n",
    "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detections = non_max_suppression(detections, conf_thres, nms_thres)\n",
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cual selecciona las mejores opciones entre las 10647\n",
    "\n",
    "1. Comprueba la confianza de presentar objeto x[:,4]\n",
    "2. Obtiene la confianza como $P(c_i|obj)$ = x[:, 5:] *= x[:, 4:5]\n",
    "3. Obtiene x1, y1, x2, y2 con los x, y, w, h\n",
    "4. Selecciona solo las cajas con alta probabilidad con su correspondiente clase\n",
    "5. Ordena por probabilidades\n",
    "6. Selecciona dado un limite\n",
    "\n",
    "Se obtine como salida un vector [bounding_box, Confianza, Clase]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafica el bouding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ML (Python 3.9.15)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detections = detections[0]\n",
    "img = np.array(Image.open('..\\data\\samples\\COCo girl.jpg'))\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "# Rescale boxes to original image\n",
    "detections = rescale_boxes(detections, img_size, img.shape[:2])\n",
    "unique_labels = detections[:, -1].cpu().unique()\n",
    "n_cls_preds = len(unique_labels)\n",
    "# Bounding-box colors\n",
    "cmap = plt.get_cmap(\"tab20b\")\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, n_cls_preds)]\n",
    "bbox_colors = random.sample(colors, n_cls_preds)\n",
    "for x1, y1, x2, y2, conf, cls_pred in detections:\n",
    "\n",
    "    print(f\"\\t+ Label: {classes[int(cls_pred)]} | Confidence: {conf.item():0.4f}\")\n",
    "\n",
    "    box_w = x2 - x1\n",
    "    box_h = y2 - y1\n",
    "\n",
    "    color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "    # Create a Rectangle patch\n",
    "    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor=\"none\")\n",
    "    # Add the bbox to the plot\n",
    "    ax.add_patch(bbox)\n",
    "    # Add label\n",
    "    plt.text(\n",
    "        x1,\n",
    "        y1,\n",
    "        s=f\"{classes[int(cls_pred)]}: {conf:.2f}\",\n",
    "        color=\"white\",\n",
    "        verticalalignment=\"top\",\n",
    "        bbox={\"color\": color, \"pad\": 0})\n",
    "\n",
    "# Save generated image with detections\n",
    "plt.axis(\"off\")\n",
    "plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
